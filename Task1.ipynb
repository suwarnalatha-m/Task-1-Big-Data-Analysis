{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+KrORvVz9so+cb/N8iPA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suwarnalatha-m/Task-1-Big-Data-Analysis/blob/main/Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVZAu042qQsm"
      },
      "outputs": [],
      "source": [
        "# Install PySpark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "M6BWaoVDwvjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CODTECH Big Data Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark Session Created Successfully\")"
      ],
      "metadata": {
        "id": "5oFeBoOTw3JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the format of the files\n",
        "!ls /content"
      ],
      "metadata": {
        "id": "Kj-iHSR1y0OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERTING Excel → CSV\n",
        "df_excel = pd.read_excel(\"/content/Online Retail.xlsx\")\n",
        "df_excel.to_csv(\"/content/online_retail.csv\", index=False)\n",
        "\n",
        "print(\"Conversion Completed\")"
      ],
      "metadata": {
        "id": "OdkMlIz4w7tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the file is in csv format\n",
        "!ls /content"
      ],
      "metadata": {
        "id": "3b_KguAbzKM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset using Pyspark\n",
        "df = spark.read.csv(\n",
        "    \"/content/online_retail.csv\",\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")"
      ],
      "metadata": {
        "id": "TEK3HLAbzjSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview\n",
        "display(\n",
        "    df.limit(10).toPandas().style\n",
        "    .set_caption(\"Online Retail Dataset Preview\")\n",
        "    .background_gradient(cmap=\"Blues\")\n",
        ")"
      ],
      "metadata": {
        "id": "D5vPGvr07045"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Rows:\", df.count())\n",
        "print(\"Total Columns:\", len(df.columns))"
      ],
      "metadata": {
        "id": "IDeaDRkz0AlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "df_clean = df.dropna()\n",
        "df_clean = df_clean.dropDuplicates()\n",
        "\n",
        "print(\"Rows after cleaning:\", df_clean.count())"
      ],
      "metadata": {
        "id": "zFBxTKkk0S3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revenue Column\n",
        "df_clean = df_clean.withColumn(\n",
        "    \"Revenue\",\n",
        "    col(\"Quantity\") * col(\"UnitPrice\")\n",
        ")\n",
        "# Preview\n",
        "display(\n",
        "    df_clean.select(\"Description\",\"Quantity\",\"UnitPrice\",\"Revenue\")\n",
        "    .limit(10)\n",
        "    .toPandas()\n",
        ")"
      ],
      "metadata": {
        "id": "u2FtpF5U0agI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top Selling Products\n",
        "top_products = df_clean.groupBy(\"Description\") \\\n",
        "    .sum(\"Quantity\") \\\n",
        "    .orderBy(col(\"sum(Quantity)\").desc())\n",
        "\n",
        "# Preview\n",
        "display(\n",
        "    top_products.limit(10).toPandas()\n",
        "    .style.background_gradient(cmap=\"Greens\")\n",
        "    .set_caption(\"Top Selling Products\")\n",
        ")"
      ],
      "metadata": {
        "id": "nEcg75Wg0tKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Country-wise Revenue\n",
        "country_sales = df_clean.groupBy(\"Country\") \\\n",
        "    .sum(\"Revenue\") \\\n",
        "    .orderBy(col(\"sum(Revenue)\").desc())\n",
        "# Preview\n",
        "display(\n",
        "    country_sales.limit(10).toPandas()\n",
        "    .style.background_gradient(cmap=\"Oranges\")\n",
        "    .set_caption(\"Revenue by Country\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "MRM-TzJN0-HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly Sales Trend\n",
        "# Extract month\n",
        "df_clean = df_clean.withColumn(\n",
        "    \"Month\",\n",
        "    month(\"InvoiceDate\")\n",
        ")\n",
        "# Aggregate\n",
        "monthly_sales = df_clean.groupBy(\"Month\") \\\n",
        "    .sum(\"Revenue\") \\\n",
        "    .orderBy(\"Month\")\n",
        "# Convert for visualization\n",
        "monthly_pd = monthly_sales.toPandas()"
      ],
      "metadata": {
        "id": "7HXtFDYD1J0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "WXGNHUToBaQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly Revenue Trend\n",
        "fig = px.line(\n",
        "    monthly_pd,\n",
        "    x=\"Month\",\n",
        "    y=\"sum(Revenue)\",\n",
        "    markers=True,\n",
        "    title=\"Interactive Monthly Revenue Trend\"\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Month\",\n",
        "    yaxis_title=\"Revenue\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "MeRPCH4zAGHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Market Contribution --> Country Revenue\n",
        "fig = px.bar(\n",
        "    country_pd,\n",
        "    x=\"sum(Revenue)\",\n",
        "    y=\"Country\",\n",
        "    orientation=\"h\",\n",
        "    title=\"Interactive Revenue by Country\",\n",
        "    text=\"sum(Revenue)\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "rjy00SB5Abva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top Products\n",
        "fig = px.bar(\n",
        "    top_products_pd,\n",
        "    x=\"sum(Quantity)\",\n",
        "    y=\"Description\",\n",
        "    orientation=\"h\",\n",
        "    title=\"Top Selling Products\"\n",
        ")\n",
        "\n",
        "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Pkq0gdMpCjDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User interactive country wise transactions\n",
        "from ipywidgets import interact\n",
        "from IPython.display import display\n",
        "\n",
        "@interact(country=country_pd[\"Country\"].tolist())\n",
        "def show_country(country):\n",
        "\n",
        "    # Filter data\n",
        "    filtered_df = (\n",
        "        df_clean\n",
        "        .filter(col(\"Country\") == country)\n",
        "        .select(\"Description\", \"Quantity\", \"UnitPrice\", \"Revenue\")\n",
        "        .limit(10)\n",
        "        .toPandas()\n",
        "    )\n",
        "\n",
        "    # Professional styled table\n",
        "    styled_table = (\n",
        "        filtered_df.style\n",
        "        .set_caption(f\"Top Transactions — {country}\")\n",
        "        .set_table_styles([\n",
        "            {\"selector\": \"th\",\n",
        "             \"props\": [(\"background-color\", \"#2c3e50\"),\n",
        "                       (\"color\", \"white\"),\n",
        "                       (\"text-align\", \"center\")]},\n",
        "            {\"selector\": \"td\",\n",
        "             \"props\": [(\"text-align\", \"center\")]},\n",
        "            {\"selector\": \"caption\",\n",
        "             \"props\": [(\"font-size\", \"16px\"),\n",
        "                       (\"font-weight\", \"bold\")]}\n",
        "        ])\n",
        "        .set_properties(**{\n",
        "            \"background-color\": \"white\",\n",
        "            \"border\": \"1px solid #ddd\"\n",
        "        })\n",
        "    )\n",
        "\n",
        "    display(styled_table)"
      ],
      "metadata": {
        "id": "Ad0xooS6C-tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCALABILITY DEMONSTRATION USING PYSPARK\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from pyspark.sql.functions import spark_partition_id\n",
        "\n",
        "print(\"\\n--- Scalability Demonstration Started ---\")\n",
        "\n",
        "# Check Original Number of Partitions\n",
        "print(\"\\nOriginal Partitions:\",\n",
        "      df.rdd.getNumPartitions())\n",
        "\n",
        "# Increase Partitions (Simulating Scalability)\n",
        "df_scaled = df.repartition(8)\n",
        "\n",
        "print(\"Partitions After Scaling:\",\n",
        "      df_scaled.rdd.getNumPartitions())\n",
        "\n",
        "# Pandas Execution Timing (Single Machine Processing)\n",
        "start = time.time()\n",
        "\n",
        "pandas_df = pd.read_csv(\"/content/online_retail.csv\")\n",
        "pandas_result = (\n",
        "    pandas_df.groupby(\"Country\")[\"Quantity\"]\n",
        "    .sum()\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"\\nPandas Total Execution Time:\",\n",
        "      f\"{end - start:.3f} seconds\")\n",
        "\n",
        "\n",
        "# PySpark Execution Timing (Original Dataset)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "df.groupBy(\"Country\").sum(\"Quantity\").show()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"PySpark Execution Time (Original):\",\n",
        "      f\"{end - start:.3f} seconds\")\n",
        "\n",
        "# PySpark Execution Timing AFTER SCALING\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "df_scaled.groupBy(\"Country\").sum(\"Quantity\").show()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"PySpark Execution Time (Scaled):\",\n",
        "      f\"{end - start:.3f} seconds\")\n",
        "# Show Partition Distribution (Proof of Parallelism)\n",
        "\n",
        "print(\"\\nPartition Distribution:\")\n",
        "df_scaled.groupBy(spark_partition_id()).count().show()\n",
        "\n",
        "\n",
        "\n",
        "# Spark Execution Plan (Distributed Processing Proof)\n",
        "\n",
        "print(\"\\nExecution Plan:\")\n",
        "df_clean.groupBy(\"Country\").sum(\"Revenue\").explain(True)\n",
        "\n",
        "print(\"\\n--- Scalability Demonstration Completed ---\")"
      ],
      "metadata": {
        "id": "u7VsaBI2HAho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analytics:**\n",
        "\n",
        "1.Sales Performance Analysis\n",
        "\n",
        "2.Revenue Trends\n",
        "\n",
        "3.Interactive Exploration\n",
        "\n",
        "4.Big Data Processing\n",
        "\n",
        "\n",
        "**Outcome:**\n",
        "\n",
        "This work demonstrated big data analysis using PySpark to clean, transform, and analyze retail transaction data for business insights.\n",
        "Scalability was shown through distributed processing and a performance comparison with Pandas, highlighting differences between single-machine and distributed frameworks.\n",
        "While Pandas performed faster on small data, PySpark proved more suitable for large-scale analytics requiring scalability and efficient processing.\n"
      ],
      "metadata": {
        "id": "_MUAXX5pHrRl"
      }
    }
  ]
}